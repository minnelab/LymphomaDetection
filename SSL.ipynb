{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Supervised Learning with Swin Transformer AutoEncoder on the AutoPET PET-CT Dataset\n",
    "\n",
    "This notebook demonstrates self-supervised learning for medical imaging using a Swin Transformer-based AutoEncoder, following the approach described by Tang et al. [1]. The model is pre-trained on the AutoPET dataset [2], which consists of whole-body FDG-PET/CT images with manually annotated tumor lesions. The aim is to leverage both PET and CT modalities in a self-supervised framework to learn robust feature representations beneficial for downstream medical image analysis tasks.\n",
    "\n",
    "---\n",
    "## Prerequisites\n",
    "\n",
    "The following packages are required to run the notebook:\n",
    "\n",
    "- `monai`\n",
    "- `torch`\n",
    "- `fire`\n",
    "- `protobuf`\n",
    "- `einops=3.20`\n",
    "- `pytorch-ignite`\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Y. Tang et al., ‘Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis’, arXiv [cs.LG]. 2021.  \n",
    "[2] S. Gatidis and T. Kuestner, ‘A whole-body FDG-PET/CT dataset with manually annotated tumor lesions (FDG-PET-CT-Lesions)’. The Cancer Imaging Archive, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import load_decathlon_datalist, Dataset, DataLoader\n",
    "from monai.data.utils import partition_dataset\n",
    "from pathlib import Path\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    CopyItemsd,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    OneOf,\n",
    "    ScaleIntensityRanged,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandCoarseDropoutd,\n",
    "    RandCoarseShuffled,\n",
    ")\n",
    "import sys\n",
    "sys.path.append(\"LymphomaDetection\")\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "from monai.losses import ContrastiveLoss\n",
    "from src.networks import SwinAutoEnc\n",
    "\n",
    "from monai.handlers import (\n",
    "    StatsHandler,\n",
    "    from_engine,\n",
    "    MeanDice,\n",
    "    ValidationHandler,\n",
    "    LrScheduleHandler,\n",
    "    CheckpointSaver,\n",
    "    CheckpointLoader,\n",
    "    TensorBoardStatsHandler,\n",
    "    MLFlowHandler,\n",
    "    IgniteMetricHandler,\n",
    "    TensorBoardImageHandler\n",
    ")\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "\n",
    "from src.utils import create_image_list, threshold_CT, prepare_batch, prepare_val_batch, mlflow_transform, tb_batch_transform, tb_output_transform\n",
    "\n",
    "from src.training import iteration\n",
    "\n",
    "from src.metrics import TotalLoss, recon_loss_transform, recon_val_loss_transform, contrastive_loss_transform, AMPContrastiveLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Data/AutoPET/PSMA-FDG-PET-CT-Lesions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_dir = Path(data_dir).joinpath(\"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = load_decathlon_datalist(data_list_file_path=Path(data_dir).joinpath(\"preprocess.json\"), base_dir=preprocess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_list = create_image_list(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = partition_dataset(image_data_list, ratios=[0.8, 0.2], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (96, 96, 96)\n",
    "\n",
    "fill_value = (0, 0.2)\n",
    "# Define Training Transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        #Spacingd(keys=[\"image\"], pixdim=(2.0, 2.0, 2.0), mode=(\"bilinear\")),\n",
    "        #ScaleIntensityRanged(\n",
    "        #    keys=[\"image\"],\n",
    "        #    a_min=-57,\n",
    "        #    a_max=164,\n",
    "        #    b_min=0.0,\n",
    "        #    b_max=1.0,\n",
    "        #    clip=True,\n",
    "        #),\n",
    "        #CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\",channel_indices=[0], select_fn=threshold_CT),\n",
    "        SpatialPadd(keys=[\"image\"], spatial_size=patch_size),\n",
    "        RandSpatialCropSamplesd(keys=[\"image\"], roi_size=patch_size, random_size=False, num_samples=2),\n",
    "        CopyItemsd(keys=[\"image\"], times=2, names=[\"gt_image\", \"image_2\"], allow_missing_keys=False),\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image\"], prob=1.0, holes=6, spatial_size=5, dropout_holes=True, max_spatial_size=32, fill_value=fill_value\n",
    "                ),\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image\"], prob=1.0, holes=6, spatial_size=20, dropout_holes=False, max_spatial_size=64, fill_value=fill_value\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image\"], prob=0.8, holes=10, spatial_size=8),\n",
    "        # Please note that that if image, image_2 are called via the same transform call because of the determinism\n",
    "        # they will get augmented the exact same way which is not the required case here, hence two calls are made\n",
    "        OneOf(\n",
    "            transforms=[\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image_2\"], prob=1.0, holes=6, spatial_size=5, dropout_holes=True, max_spatial_size=32, fill_value=fill_value\n",
    "                ),\n",
    "                RandCoarseDropoutd(\n",
    "                    keys=[\"image_2\"], prob=1.0, holes=6, spatial_size=20, dropout_holes=False, max_spatial_size=64, fill_value=fill_value\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        RandCoarseShuffled(keys=[\"image_2\"], prob=0.8, holes=10, spatial_size=8),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataLoader using MONAI, CacheDataset needs to be used\n",
    "batch_size = 2\n",
    "train_ds = Dataset(data=train_data, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = Dataset(data=val_data, transform=train_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_data, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "\n",
    "image = check_data[\"image\"][0][0]\n",
    "print(f\"image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 1\n",
    "channel_id = 0\n",
    "fig, axs = plt.subplots(3,3,figsize=(20*3, 20))\n",
    "z_center = int(check_data[\"image\"][batch_id][channel_id].shape[-1]/2)\n",
    "y_center = int(check_data[\"image\"][batch_id][channel_id].shape[-2]/2)\n",
    "x_center = int(check_data[\"image\"][batch_id][channel_id].shape[-3]/2)\n",
    "axs[0,0].imshow(check_data[\"image\"][batch_id][channel_id,:,:,z_center],cmap='gray')\n",
    "axs[0,1].imshow(check_data[\"image\"][batch_id][channel_id, :,y_center,:],cmap='gray')\n",
    "axs[0,2].imshow(check_data[\"image\"][batch_id][channel_id, x_center,:,:],cmap='gray')\n",
    "\n",
    "axs[1,0].imshow(check_data[\"image_2\"][batch_id][channel_id,:,:,z_center],cmap='gray')\n",
    "axs[1,1].imshow(check_data[\"image_2\"][batch_id][channel_id, :,y_center,:],cmap='gray')\n",
    "axs[1,2].imshow(check_data[\"image_2\"][batch_id][channel_id, x_center,:,:],cmap='gray')\n",
    "\n",
    "axs[2,0].imshow(check_data[\"gt_image\"][batch_id][channel_id,:,:,z_center],cmap='gray')\n",
    "axs[2,1].imshow(check_data[\"gt_image\"][batch_id][channel_id, :,y_center,:],cmap='gray')\n",
    "axs[2,2].imshow(check_data[\"gt_image\"][batch_id][channel_id, x_center,:,:],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network ViT backbone & Loss & Optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = SwinAutoEnc(\n",
    "    in_chans=2,\n",
    "    out_channels=2,\n",
    "    embed_dim=96,\n",
    "    window_size=(4, 4, 4),\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 6, 2),\n",
    "    num_heads=(3, 6, 12, 24),\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Hyper-paramters for training loop\n",
    "max_epochs = 500\n",
    "val_interval = 2\n",
    "\n",
    "lr = 1e-4\n",
    "best_val_loss = 1000.0\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = L1Loss()\n",
    "contrastive_loss = ContrastiveLoss(temperature=0.05)\n",
    "\n",
    "\n",
    "total_loss = TotalLoss(\n",
    "    recon_loss=recon_loss,\n",
    "    contrastive_loss=contrastive_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir_path = os.path.normpath(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_val_metric = IgniteMetricHandler(loss_fn=recon_loss,output_transform=recon_val_loss_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"models\"\n",
    "log_dir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_handlers = [StatsHandler(iteration_log=False)]\n",
    "val_handlers.append(\n",
    "    CheckpointSaver(\n",
    "        save_dir=ckpt_dir,\n",
    "        save_dict={\n",
    "            \"model\": model,\n",
    "            \"optimizer_state\": optimizer,\n",
    "            #\"scheduler\": lr_scheduler,\n",
    "        },\n",
    "        # save_final= True,\n",
    "        save_interval=1,\n",
    "        key_metric_negative_sign=True,\n",
    "        save_key_metric=True,\n",
    "        # final_filename= \"model_final.pt\",\n",
    "        #key_metric_filename= \"model.pt\",\n",
    "        n_saved=1,\n",
    "    )\n",
    ")\n",
    "val_handlers.append(TensorBoardStatsHandler(log_dir=log_dir, iteration_log=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_handlers.append(TensorBoardImageHandler(log_dir=log_dir, batch_transform=tb_batch_transform, output_transform=tb_output_transform,max_channels=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = SupervisedEvaluator(\n",
    "    amp=True,\n",
    "    device=device,\n",
    "    epoch_length=2,\n",
    "    network=model,\n",
    "    key_val_metric={\"Val_Reconstruction_Loss\": key_val_metric},\n",
    "    prepare_batch=prepare_val_batch,\n",
    "    val_data_loader=val_loader,\n",
    "    val_handlers=val_handlers,\n",
    "    #postprocessing=postprocessing,\n",
    "    #additional_metrics=additional_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_handlers = [StatsHandler(output_transform=from_engine([\"loss\"], first=True), tag_name=\"train_loss\"), ValidationHandler(epoch_level=True, interval=1, validator=evaluator)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_handlers.append(\n",
    "    TensorBoardStatsHandler(log_dir=log_dir, output_transform=from_engine([\"loss\"], first=True), tag_name=\"train_loss\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_experiment_name = \"SwinAutoEnc\"\n",
    "mlflow_run_name = \"SwinAutoEnc_Train\"\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "\n",
    "train_handlers.append(\n",
    "    MLFlowHandler(\n",
    "        dataset_dict={\"train\": train_data},\n",
    "        dataset_keys=\"image\",\n",
    "        #experiment_param=create_mlflow_experiment_params(params_file),\n",
    "        experiment_name=mlflow_experiment_name,\n",
    "        #label_dict=label_dict,\n",
    "        output_transform=mlflow_transform,\n",
    "        run_name=mlflow_run_name,\n",
    "        state_attributes=[\"best_metric\", \"best_metric_epoch\"],\n",
    "        tag_name=\"Train_Loss\",\n",
    "        tracking_uri=tracking_uri,\n",
    "    )\n",
    ")\n",
    "\n",
    "val_handlers.append(\n",
    "    MLFlowHandler(\n",
    "        experiment_name=mlflow_experiment_name,\n",
    "        iteration_log=False,\n",
    "        #label_dict=label_dict,\n",
    "        output_transform=mlflow_transform,\n",
    "        run_name=mlflow_run_name,\n",
    "        state_attributes=[\"best_metric\", \"best_metric_epoch\"],\n",
    "        tracking_uri=tracking_uri,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss_metric = L1Loss()\n",
    "contrastive_loss_metric = AMPContrastiveLoss(temperature=0.05)\n",
    "\n",
    "additional_metric = IgniteMetricHandler(loss_fn=contrastive_loss_metric,output_transform=contrastive_loss_transform)\n",
    "train_key_metric = IgniteMetricHandler(loss_fn=recon_loss_metric,output_transform=recon_loss_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\n",
    "    device=\"cuda\",\n",
    "    max_epochs=500,\n",
    "    train_data_loader=train_loader,\n",
    "    network=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=total_loss,\n",
    "    inferer=None,\n",
    "    key_train_metric={\"Reconstruction_Loss\": train_key_metric},\n",
    "    train_handlers=train_handlers,\n",
    "    additional_metrics={\"Contrastive_Loss\": additional_metric},\n",
    "    amp=True,\n",
    "    prepare_batch=prepare_batch,\n",
    "    iteration_update=iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training as a MONAI Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import yaml\n",
    "\n",
    "def create_config(config_folder, output_file):\n",
    "    config_files = [f.path for f in os.scandir(config_folder) if f.path.endswith(\".yaml\")]\n",
    "    config = {}\n",
    "    for config_file in config_files:\n",
    "        with open(config_file, \"r\") as file:\n",
    "            config.update(yaml.safe_load(file))\n",
    "\n",
    "    if output_file.endswith(\".yaml\"):\n",
    "        with open(output_file, \"w\") as file:\n",
    "            yaml.dump(config, file)\n",
    "    if output_file.endswith(\".json\"):\n",
    "        with open(output_file, \"w\") as file:\n",
    "            json.dump(config, file)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p LymphomaDetection/SSL/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_config(\"LymphomaDetection/Bundles/SSL\", \"LymphomaDetection/SSL/configs/train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r LymphomaDetection/src LymphomaDetection/SSL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export BUNDLE_ROOT=\"LymphomaDetection/SSL\"\n",
    "export PYTHONPATH=$BUNDLE_ROOT\n",
    "export DATA_FOLDER=Data/AutoPET/PSMA-FDG-PET-CT-Lesions\n",
    "\n",
    "cd $BUNDLE_ROOT\n",
    "python -m monai.bundle run \\\n",
    "    --bundle_root $BUNDLE_ROOT \\\n",
    "    --data_dir $DATA_FOLDER/preprocessed \\\n",
    "    --decathlon_data_list $DATA_FOLDER/preprocess.json \\\n",
    "    --tracking_uri \"http://localhost:5000\" \\\n",
    "    --config_file $BUNDLE_ROOT/configs/train.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
